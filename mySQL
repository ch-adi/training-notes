start up mysql terminal: mysql-ctl cli
end mysql session with the `exit` command

SHOW DATABASES;
CREATE DATABASE <database_name>;
USE <database_name>;
SELECT database();   // shows the currently selected database
CREATE TABLE <table_name> ( <column_name> <data_type} <NOT NULL DEFAULT 'unnamed'>, ... );  // datatypes incl INT and VARCHAR(<int>).  // null means unkown value rather than 0;  Can still be applie don INSERT if NOT NULL isn't specified.
SHOW TABLES;
DESC <table_name>;  // aka SHOW COLUMNS FROM <table_name>;
DROP TABLE <table_name>;
DROP DATABASE <database_name>;
INSERT INTO <table_name>(column_name, ...) VALUES (value, ...) , (value, ...) , ...; // values order must match column order
SELECT * FROM <table_name>;
SHOW WARNINGS; // only works as the very next command after a warning is generated
A primary key is a unique identifier on a row.
    
Unique primary key (with auto increment for integer key: no need to supply when inserting). Could also make a string unique but you 
// may well wont to allow duplicates of names for example, especially if it is a default name.
CREATE TABLE unique_cats2 (
        cat_id INT NOT NULL AUTO_INCREMENT,
         name VARCHAR(100),
         age INT,
         PRIMARY KEY (cat_id)
     );

 or 

 CREATE TABLE unique_cats2 (
         cat_id INT NOT NULL AUTO_INCREMENT PRIMARY KEY,
         name VARCHAR(100),
         age INT
     );
	 
Here there are two unique fields. While the username should be unique we still want a an id as the primary key. id is a lot easier to search out.

	 
    CREATE TABLE users (
        id INTEGER AUTO_INCREMENT PRIMARY KEY,
        username VARCHAR(255) UNIQUE NOT NULL,
        created_at TIMESTAMP DEFAULT NOW()
    );
	
An insert here only requires a username value. Everything else will be autogenerated.
	INSERT INTO users (username) VALUES ('bob');

WHERE <column_name> <comparative operator> <value>  // you seldom want all results so filters the table_name. case insenstive
Operators include !=, > , etc. AND is equivalent to && (depreciated) and allows for 2 or more additional conditions. EG:
SELECT title, released_year FROM books WHERE released_year > 2010 && author_lname = 'Eggers'; // same as:
SELECT title, released_year FROM books WHERE released_year > 2010 AND author_lname = 'Eggers'; 
SELECT * FROM books WHERE 
	author_lname='Eggers' 
    AND released_year > 2010 
    AND title LIKE '%novel%';     // 3 conditions (LIKE is discussed below)
SELECT title, released_year FROM books WHERE released_year > 2010 OR author_lname = 'Eggers' // OR aka || example
The IN operator can tidy up a chanin of ORs:

SELECT title, author_lname FROM books
WHERE author_lname='Carver' OR 
author_lname='Lahiri' OR 
author_lname='Smith';  // same as:

SELECT title, author_lname FROM books
WHERE author_lname IN ('Carver', 'Lahiri', 'Smith');

IN takes in a set and returns 0 if false and 1 if true.
SELECT 1 IN (5, 3); // 0

NOT IN is the opposite. (replace a chain !== AND operators).

A modulo operator also exists. EG all odd years after 1999:
SELECT title, released_year FROM books
WHERE released_year >= 2000 AND released_year % 2 != 0 ORDER BY released_year;



Alias is useful, eg same col name from 2 different tables. Simple example:
SELECT cat_id  AS 'id', age AS 'years' FROM cats WHERE cat_id=age;

BETWEEN can be used to replace AND if conditions are on the same value. EG replace eleased_year >= 2004 AND released_year <= 2015
SELECT title, released_year FROM books WHERE released_year BETWEEN 2004 AND 2015; // NOT BETWEEN is the opposite and BETEEEN in inclusive



Updating: Select before you update: double check you are changing the correct database_name
UPDATE <table_name> SET <column_name>=value WHERE <column_name>=<value>; // eg
UPDATE cats SET breed='Shorthair' WHERE breed='Tabby';
UPDATE shirts SET shirt_size='XS', color='off white' WHERE color='white';

DELETE FROM <table_name>;  // delete all rows in a table but not the table (that is DROP)
DELETE FROM <table_name> WHERE <column_name>=value; // delete specific rows

CONCAT combines columns when running a SELECT.
CONCAT(<column_name> |'<some text>', <column_name> |'<some text>', ...) FROM <table_name>;
Single argumement to SELECT but using AS to make the table title look better:
SELECT CONCAT(author_fname, ' ', author_lname) AS 'Full Name' FROM books;
Multipe coolumns in the result:
SELECT author_fname AS first, author_lname AS last, 
   CONCAT(author_fname, ' ', author_lname) AS full
FROM books;
CONCAT_WS(<text used as space betwenn following argumnet>, <column_name> |'<some text>', ...);


SUBSTRING allows you to work with part of a string. 2nd arg counts from 1 not zero. Can be a negative index.
SELECT SUBSTRING('Hello World', 1, 4);  //Hell
SELECT SUBSTRING('Hello World', 7);  //World
SELECT SUBSTRING('Hello World', -7); //o World
SELECT CONCAT
    (
      SUBSTRING(title, 1, 10),
        '...'
    ) AS 'short title'
FROM books;
// all books whose author's last name starts with 'C' or 'S':
SELECT title, author_lname FROM books 
WHERE SUBSTR(author_lname,1,1) IN ('C', 'S');


 SELECT REPLACE('<text>' | <column_name>, '<char to replace>', '<new char>'); // eg SELECT REPLACE('HellO World', 'o', '*');
 EG: take the first 10 letters of each entry and replace
 SELECT SUBSTRING(REPLACE(title, 'e', '3'), 1, 10) AS 'weird string' FROM books;
 SELECT REVERSE(<column_name> | '<string>');
 CHAR_LENGTH(<column_name> | '<text>');
 SELECT  CONCAT ( author_lname, ' is ', CHAR_LENGTH(author_lname), ' characters long' ) as 'Name Length' FROM books;
 UPPER() and LOWER() change the case of a string.

 DISTINCT is used with SELECT to obtain unique values. DISTINCT applys to all passed in columns
 SELECT DISTINCT author_lname, author_fname FROM books;  // stops the loss of data: some people have the same last name and we dont want to exlude them

Alphabetacal or number order with ORDER BY. Ascending by dafault. Otherise use DESC on the end of the query. The argument is either a colum or int (for SELECT argument order)
SELECT released_year FROM books ORDER BY released_year DESC;  //order by the most recent year 
SELECT author_lname, author_fname, released_year FROM books ORDER BY 2; //order by the second argument, which is author_fname. ASC is implied on the end if DESC not specified
SELECT author_fname, author_lname FROM books ORDER BY author_lname, author_fname; // order on the last name and then if two rows are the same order on the first name.
SELECT title, released_year FROM books WHERE released_year < 2000 ORDER BY released_year; // order books made before 2000

LIMIT specifies how many rows you would like.
SELECT title, released_year FROM books ORDER BY released_year DESC LIMIT 5;  // 5 most recent books
SELECT title FROM books LIMIT 5, 7;   // displays 7 rows, starting from the 6th row (counts in the normal CS fashion)

LIKE filters with more options than a plane WHERE, which is otherwise is more exact in that you must know the exact row value and use a logical operator.
% is a zero or more characters wild card. Normal characters are case insensitive.
SELECT author_fname FROM books WHERE author_fname LIKE '%da%';  // all first names that contain a 'da': freida, Dan, ...
SELECT author_fname FROM books WHERE author_fname LIKE 'da%'; // all first names that start with 'da': Dan but not freida
underscore, _, specifies exactly one character. EG you want 2 digit stock quantities:
SELECT title, stock_quantity FROM books WHERE stock_quantity LIKE '__';
phone number pattern: (235)234-0987 LIKE '(___)___-____'
use an escape '\' if there is an underscore or % in a value
SELECT title FROM books WHERE title LIKE '%10\%%'; //finds a title with value '10% Happier'
SELECT title FROM books WHERE title NOT LIKE 'W%'; // NOT makes an opposite selection: all books that do not begin with a 'W'

Aggregate functions and GROUP BY
MIN, MAX, AVG. SUM and COUNT all group rows and thus risk misleading results
SELECT COUNT(*) FROM books;    //a total row count of the table
SELECT COUNT(DISTINCT author_fname, author_lname) FROM books;   //count all distinct authors. EG will count both Freda Miller and Francis Miller
SELECT COUNT(*) FROM books WHERE title LIKE '%the%';  // all titles that contain a 'the'
SELECT author_fname, author_lname, Count(*) FROM books; // Will group all 19 entries in 1 row.
GROUP BY summarizes or aggregates identical data into single 'super rows'.
SELECT author_lname, Count(*) FROM books GROUP BY author_lname;  // will give you a count for each time the same surname appears in the table
Very easy to mis-understand the result. Since GROUP BY aggregate all matching rows into one super row (from which you can then further filter results), if you want to see other columns they only show the info from the first matching.mysql0ctl cli
SELECT author_fname, author_lname, Count(*) FROM books GROUP BY author_lname;  // displays Dan | Harris | 2 . // Freida Harris is grouped into the count but you dont see her data. // Fix:
SELECT author_fname, author_lname, Count(*) FROM books GROUP BY author_lname, author_fname;
SELECT MAX(pages), title FROM books; // (MIN() is similar.) title of longest book?? NO!!! Grouping is occuring again.
SQL finds MAX(pages) first. It then needs something to fill in for title and does that 2nd. Both operations are independant. 
The answer is to run two queries:
SELECT title, pages FROM books WHERE pages = (SELECT MAX(pages) FROM books);
However, to save computations just use ORDER BY:
SELECT title, pages FROM books ORDER BY pages DESC LIMIT 1;

First year each author published [it's like we are making a bunch of sub-table with group by and then selecting from that]:
SELECT author_fname AS 'First Name', author_lname as 'Last Name', MIN(released_year) 
FROM books
GROUP BY author_lname, author_fname;

SELECT SUM(pages) FROM books; // all the page counts added together.

SELECT CONCAT(author_fname, ' ', author_lname) AS 'author', SUM(pages) FROM books GROUP BY author_lname, author_fname; // Total pages written by each author

SELECT AVG(released_year) FROM books; // average released year across all books
SELECT released_year, AVG(stock_quantity) FROM books GROUP BY released_year; // stock levels across year



Data Types

CHAR has a fixed length. eg CHAR(3) - only 3 characters are allowed and right padding with spaces occurs in storage. The padding is dropped at retrieval. It is slightly faster faster than VARCHAR, and if it's small enough it may use slightly less memory. Possible uses are limited but do include state codes (CA, NY) Sex (M/F) or flags (Y/N).

INT for whole numners
DECIMAL(13,2); // decimal number with 13 total digits, with 2 of those digits coming after the point.
FLOAT and DOUBLE // unlike decimal calcs with these types are not exact. Store larger numbers with less space.
FLOAT has precison issues from around 7 digits. DOuble have double the memory but good to 15 digits.

DATE // stores a date but without time 'YYYY-MM-DD' (insert with quote marks like a string)
TIME // time with no date 'HH:MM:SS'
DATETIME // 'YYYY-MM-DD HH:MM:SS'  eg '1943-12-25 04:10:42'

CREATE TABLE people (birth DATETIME);
INSERT INTO people(birth) VALUES ('1943-12-25 04:10:42');

SELECT NOW(); get the current date-time in DATETIME format
SELECT CURDATE(); // get the current date in DATE format eq to SELECT DATE(NOW());
SELECT CURTIME(); // get the current date in TIME format 

For date or time value selections you may want to first CAST() for better comparisons.
SELECT name, birthdt FROM people WHERE 
    birthdt BETWEEN CAST('1980-01-01' AS DATETIME) AND CAST('2000-01-01' AS DATETIME);


INSERT INTO people(birth) VALUES (NOW());

Format date with DAY(), DAYNAME(), DAYOFWEEK(), DAYOFYEAR(). Match with the correct type. More available.
SELECT name, birthdate, DAYOFWEEK(birthdate) FROM people; // 'padma' | 1983-11-11 | 6
Convert '2018-04-21' to 'April 21 2017' in in a selection in 2 ways:
CONCAT(MONTHNAME(birthdate), ' ', DAY(birthdate), ' ', YEAR(birthdate))  // Or easier way with DATEFORMAT that has a variety of format codes:
SELECT DATE_FORMAT(birthdt, '%m/%d/%Y at %h:%i') FROM people; // 04/11/2019 10:20
SELECT DATE_FORMAT(now(), '%m/%d/%Y'); //current date

side note: pretty much everything in mqSQL that accepts date will also accept date time.

Date Math:

DATEDIFF for a difference:
SELECT DATEDIFF(NOW(), birthdate) FROM people; // life length in days
DATE_ADD, DATE_SUB and +/- are equivalent. You need INTERNAL which has various
units like DAY MONTH SECOND and QUARTER.
SELECT birthdt, birthdt + INTERVAL 1 MONTH FROM people; //same as:
SELECT birthdt, DATE_ADD(birthdt, INTERVAL 1 MONTH) FROM people;
SELECT birthdt, birthdt + INTERVAL 15 MONTH + INTERVAL 10 HOUR FROM people; //multiple units

TIMESTAMP is an alternative data type to DATETIME. It has a much more limited range (1970 - 2038), but does use less memory. Limited use except for meta time data:

// tables with a row creation time
CREATE TABLE comments (
    content VARCHAR(100),
    created_at TIMESTAMP DEFAULT NOW()
);
INSERT INTO comments (content) VALUES('I found this offensive');

// here the TIMESTAMP will update if the row updates:
CREATE TABLE comments2 (
    content VARCHAR(100),
    changed_at TIMESTAMP DEFAULT NOW() ON UPDATE CURRENT_TIMESTAMP
);
INSERT INTO comments2 (content) VALUES('dasdasdasd');
UPDATE comments2 SET content='THIS IS NOT GIBBERISH' WHERE content='dasdasdasd';

An equivlent to CURRENT_TIMESTAMP:
changed_at TIMESTAMP DEFAULT NOW() ON UPDATE NOW()


CASE statements: WHEN/THEN/ELSE [ie IF/ELSE]
A way to add a new column with computed info.

A new genre column:
SELECT title, released_year,
       CASE 
         WHEN released_year >= 2000 THEN 'Modern Lit'
         ELSE '20th Century Lit'
       END AS GENRE
FROM books;

A little graph indicating stock size:

SELECT title, stock_quantity,
    CASE 
        WHEN stock_quantity BETWEEN 0 AND 50 THEN '*'
        WHEN stock_quantity BETWEEN 51 AND 100 THEN '**'
        ELSE '***'
    END AS STOCK
FROM books;

Since WHEN is processes in turn, this is equivalent:

SELECT title, stock_quantity,
    CASE 
        WHEN stock_quantity <= 50 THEN '*'
        WHEN stock_quantity <= 100 THEN '**'
        ELSE '***'
    END AS STOCK
FROM books;

Here we reuse a CASE in a late GROUP BY, to get a count of all user email providers:

	SELECT 
	CASE
		WHEN email LIKE '%@gmail.com' THEN 'gmail'     // not missing last % - the email must end with a domain.
		WHEN email LIKE '%@yahoo.com' THEN 'yahoo'
		WHEN email LIKE '%@hotmail.com' THEN 'hotmail'
		ELSE 'other'
	 END AS provider, 
	 COUNT(*) AS total_users
	FROM users
	GROUP BY provider;


Sometimes you can just get away with an IF. The following are identical:

    CASE
        WHEN COUNT(rating) > 0 THEN 'ACTIVE'
        ELSE 'INACTIVE'
    END AS 'STATUS'

IF(Count(rating) > 0, 'ACTIVE', 'INACTIVE') AS STATUS 



Data Relationships

One to one relationship dont see often. One example might be cut down customer details row in one table. In another table, that same customer will have more details recorded. Again, though, each row relates to a single customer.

One to many relationship. Most common. EG one book (one row in the books table) has many review rows associated with it in the Reviews table. Books have many reviews but a review belongs to one book. Another example is customers to orders. One customer (one row in a customer table) has many orders from the order table. But each order only relates to one customer.

Many to many relationship: eg books can have many authors (like a uni paper) and any one author can have many books.


Why not place everything in one table? Well you possibly could, but there would be heaps of duplication, and lots of computation required to work through that table. 


One to Many

OTM works on a unique primary key from the 'one' table being referenced by each relevant row in the 'many' table. The row in the 'many table will have it's primary key. However that is not the reference back to row in the 'one' table. Rather, that is known as a 'foreign key'. 

By convention the foreign key has the name of the table it comes from, followed by underscore and then the key. This prevents a naming collision, which would happen in the following example where both tables have their own primary key called id.

To specify a foreign key use, as an argument in CREATE TABLE:
FOREIGN KEY(otherTableName_keyNameInOtherTable), REFERENCES tableName(keName)

This prevents inserting a foreign key that does not exist.

    CREATE TABLE customers(
        id INT AUTO_INCREMENT PRIMARY KEY,
        first_name VARCHAR(100),
        last_name VARCHAR(100),
        email VARCHAR(100)
    );
	
    CREATE TABLE orders(
        id INT,
        order_date DATE,
        amount DECIMAL(8,2),
        customer_id INT,
        FOREIGN KEY(customer_id) REFERENCES customers(id)
    );
	
How to get the data out?
This, called a cross join (aka implicit join), is completly useless:

SELECT * FROM customers, orders; // will get every possible row combination between the two tables

Something better is an implicit inner join. This gets all data that matches both tables and makes meaningful rows. (inner/overlap part of a Venn diagram). here the condition for a match between tables is in the WHERE.

    SELECT * FROM customers, orders 
    WHERE customers.id = orders.customer_id;
	
Even better is an explicit inner join:

SELECT * FROM customers
INNER JOIN orders             // can leave INNER out: it is the implied join type
    ON customers.id = orders.customer_id;

An inner join collects all the records that match the 'inner join condition'.


Say if you wanted all orders from each customer you might try a sub query:

    SELECT * FROM orders WHERE customer_id =
        (
            SELECT id FROM customers
            WHERE last_name='George'
        );
		
But again there is a better way:

SELECT * FROM customers
JOIN orders ON customers.id = orders.customer_id
WHERE customers.last_name='George';

You can add any sql table functions on these tables, such as ORDER BY and GROUP BY.
Here we find the person who has placed the largest order:

SELECT first_name, last_name, MAX(amount) FROM customers
JOIN orders ON customers.id = orders.customer_id
GROUP BY customers.id
ORDER BY 3 DESC LIMIT 1;

Or top 3 overall largest spenders:

SELECT first_name, last_name, SUM(amount) AS total_spent FROM customers
JOIN orders ON customers.id = orders.customer_id
GROUP BY customers.id
ORDER BY total_spent DESC LIMIT 3;


LEFT JOIN:

takes everything from the first table along with any matching records from the the second table.
If we modify the example above we will get all cutomers, including those who have not placed orders
(ie no mtach in the order table). NULL is displayed for those extra columns that do not have a match (no orders for that customer yet).

You can remove null with IFNULL. Here we show total order value again.

SELECT first_name, last_name, IFNULL(SUM(amount), 0) as 'Total Order Value'  FROM customers
LEFT JOIN orders                      
    ON customers.id = orders.customer_id
GROUP BY customers.id;

Right Join

Just the opposite of a left join (in fact you could just flip the order of the tables in a JOIN statement). In our case we don't expect a big difference from an inner join. Every order in our order table should have a cutomer associated with it. However, if someone had made an error in the table, such as deleting a customer but not their associated orders a right join would pick up nulls. Error detection:

SELECT * FROM customers
RIGHT JOIN orders    // see NULL for customer table entries - orphan data
    ON customers.id = orders.customer_id;

So how do you automatically delete orders when the customer is deleted? Use ON DELETE CASCADE.

CREATE TABLE orders(
    order_date DATE,
    amount DECIMAL(8,2),
    customer_id INT AUTO_INCREMENT PRIMARY KEY,
    FOREIGN KEY(customer_id) 
        REFERENCES customers(id)
        ON DELETE CASCADE
);

If you delete a customer their associated orders will also be deleted.


Many to Many

Examples include 
 - books to authors (it's possible to have more than one author for a book and one author can write more than one book).
 - blog posts <-> tags
 - students <-> classes
 - reviewers <-> TV series reviews
 
 We will do the last eample, which requires three tables. Series and reviewers tables are linked through a reviews table.
 So the reviews table is known as a joined or union table.
 

CREATE TABLE reviews (
    id INT AUTO_INCREMENT PRIMARY KEY,
    rating DECIMAL(2, 1),
    series_id INT,
    reviewer_id INT,
    FOREIGN KEY(series_id) 
        REFERENCES series(id)
        ON DELETE CASCADE,
    FOREIGN KEY(reviewer_id) 
        REFERENCES reviewers(id)
        ON DELETE CASCADE
);

Joins work in the same way:

SELECT first_name, last_name, rating FROM reviewers
INNER JOIN reviews
    ON reviewers.id = reviews.reviewer_id;

What about selecting data that is not in the union table? A LEFT JOIN will take
eveything from the first table before then applying the join condition. So you will
see null for an unreviewed series:

SELECT title AS 'unreviewed_series' FROM series
LEFT JOIN reviews
    ON series.id = reviews.series_id;
	
Now you can use WHERE for the null entries,, remembering that you cannot use =NULL in SQL, but rather IS NULL:

SELECT title AS 'unreviewed_series' FROM series
LEFT JOIN reviews
    ON series.id = reviews.series_id
WHERE reviews.rating IS NULL;

LEFT JOIN highlights discrepanices.


When we want information from all 3 tabales we need two joins:

    SELECT 
        title,
        rating,
        CONCAT(first_name,' ', last_name) AS reviewer
    FROM reviewers
    INNER JOIN reviews 
        ON reviewers.id = reviews.reviewer_id
    INNER JOIN series
        ON series.id = reviews.series_id
    ORDER BY title;


Another union table example is from instagram. A user likes their own or another user's picture. But, that like does not need it's own id. We will never refer to it anywhere else other than with a photo for a certain user. Having a user id and a photo id in the table as foreign keys is enough. However, a user cannot like an image more than once. This means we need a primary key that is some unique combination of unique values: the photo and user ids. PRIMARY KEY can take both values.

    CREATE TABLE likes (
        user_id INTEGER NOT NULL,
        photo_id INTEGER NOT NULL,
        created_at TIMESTAMP DEFAULT NOW(),
        FOREIGN KEY(user_id) REFERENCES users(id),
        FOREIGN KEY(photo_id) REFERENCES photos(id),
        PRIMARY KEY(user_id, photo_id)
    );
	
	INSERT INTO likes(user_id, photo_id) VALUES (1, 2);
	INSERT INTO likes(user_id, photo_id) VALUES (1, 2); // duplicate entry warning
	INSERT INTO likes(user_id, photo_id) VALUES (2, 1); // permitted
	
	
A follows table also does not need an id. We will not reference it anywhere. And again we also need to make sure each relationship is unique.

    CREATE TABLE follows (
        follower_id INTEGER NOT NULL,
        followee_id INTEGER NOT NULL,
        created_at TIMESTAMP DEFAULT NOW(),
        FOREIGN KEY(follower_id) REFERENCES users(id),
        FOREIGN KEY(followee_id) REFERENCES users(id),
        PRIMARY KEY(follower_id, followee_id)
    );
	
Hash tags on a photo should be searchable. If you search a hastag then associated photos should appear. Also, if you click on a hashtag all other photos with that hashtag sould appear. There are many ways to solve the problem. We will use a join table called photo_tags. It connects photos and tags. We do have to worry about orphans. 

    CREATE TABLE tags (
      id INTEGER AUTO_INCREMENT PRIMARY KEY,
      tag_name VARCHAR(255) UNIQUE,
      created_at TIMESTAMP DEFAULT NOW()
    );
	
    CREATE TABLE photo_tags (
        photo_id INTEGER NOT NULL,
        tag_id INTEGER NOT NULL,
        FOREIGN KEY(photo_id) REFERENCES photos(id),
        FOREIGN KEY(tag_id) REFERENCES tags(id),
        PRIMARY KEY(photo_id, tag_id)
    );

Who has the most popular photo?

SELECT 
    username,
    image_url,
    COUNT(*) AS total_likes
FROM photos
INNER JOIN likes
    ON photos.id = likes.photo_id
INNER JOIN users
    ON photos.user_id = users.id
GROUP BY likes.photo_id
ORDER BY total_likes DESC
LIMIT 1;

What about getting an average of posts per user? No fancy joins are needed:

SELECT (SELECT COUNT(*) FROM photos ) / (SELECT COUNT(*) FROM users) AS 'avg';

Another possibility, more verbose option:

SELECT 
    COUNT(image_url) AS num_photos,
    COUNT(DISTINCT users.id) AS num_users,
    COUNT(image_url)/COUNT(DISTINCT users.id) AS average_photos
FROM users
LEFT JOIN photos
	ON users.id = photos.user_id;


Most popular hash tags:

	SELECT tag_name, COUNT(*) AS total FROM photo_tags
	RIGHT JOIN tags 
		ON tags.id = photo_tags.tag_id
	GROUP BY tag_id
	ORDER BY total DESC
	LIMIT 5;
	

HAVING

What about finding users who have liked every photo? They are probably bots. So we need a sub query to get the total number of photos. However, while we can get a count on likes, we cannot follow a GROUP BY with a WHERE count = ... . Instead use HAVING, which works in the same way:

    SELECT username, 
           Count(*) AS num_likes 
    FROM   users 
           INNER JOIN likes 
                   ON users.id = likes.user_id 
    GROUP  BY likes.user_id 
    HAVING num_likes = (SELECT Count(*) FROM   photos); 

Otherwise it might look like this mess:

SELECT username, total FROM (
    SELECT 
        username, 
        COUNT(*) AS total
    FROM users
    INNER JOIN likes
        ON users.id = likes.user_id
    GROUP BY username
) AS newTable
WHERE total = (SELECT COUNT(*) FROM photos);
	

Node and MySQL

npm install mysql // package that communicates between node and mysql

node fileName.js  // run the following fileName.js file:

	const faker = require('mysql');

	var connection = mysql.createConnection({
	  host     : 'localhost',
	  user     : 'root',     // your username
	  database : 'joinus'   // the name of your db
	});

	const query = 'SELECT 1 + 1 AS solution, CURDATE() as date'

	connection.query(query, function (error, results, fields) {
		   if (error) throw error;
		   console.log(results[0].solution, results[0].date);
		});

	connection.end();   // leave this at the end of the script.



Each table row will have an entry in the results array

For efficiency reasons let mysql do the work. Otherwise there may be too mcuh data to transfer. For example if we want a count of all users then make your query do a COUNT(*). Don't use results.length in the callback.

const query = 'SELECT COUNT(*) from users' // not SELECT * from users

connection.query(query, function (error, results, fields) {
       if (error) throw error;
       console.log(results); // not results.length
    });

This node library also allows us to enter objects. In an insert operation any keys from those objects will be interpreted as columns names. Here we an insert a user, which requires values for email and created_at:

    var person = {
        email: faker.internet.email(),
        created_at: faker.date.past()
    };
     
    var end_result = connection.query('INSERT INTO users SET ?', person, function(err, result) {
      if (err) throw err;
      console.log(result);
    });


What about inserting 500 users? We could run 500 queries in a loop but it is more efficient to first generate the user and do a bulk insert; insert all the users at once. This requires an array or arrays rather than one object.

	var data = [];
	for(var i = 0; i < 500; i++){
		data.push([
			faker.internet.email(),
			faker.date.past()
		]);
	}

	var q = 'INSERT INTO users (email, created_at) VALUES ?';

	connection.query(q, [data], function(err, result) {
	  console.log(err);
	  console.log(result);
	});



Database Triggers
-----------------------------

There are several user cases for triggers. 

1. Data validation. However, there is a strong argument to just handle this on the server side and save an expensive DB query back through the server. An example is not accepting a user who does not meet age requirments: 

	DELIMITER $$

	CREATE TRIGGER must_be_adult
		 BEFORE INSERT ON users FOR EACH ROW
		 BEGIN
			  IF NEW.age < 18
			  THEN
				  SIGNAL SQLSTATE '45000'
						SET MESSAGE_TEXT = 'Must be an adult!';
			  END IF;
		 END;
	$$

	DELIMITER ;

	INSERT INTO users(username, age) VALUES ('Yang', 17); // ERROR: Must be an adult! 


The key line is: BEFORE INSERT ON users FOR EACH ROW
BEFORE: the trigger can also run AFTER an event:
INSERT: can also be DELETE or UPDATE events
FOR EACH ROW is boiler plate

In the THEN block we generate an SQL error. It requires an error code, a SQLSTATE, and a message string. Check out the online docs for good codes. 45000 represents an unhandled user defined exception.

DEMLIMTER and $$ stop all the semi-colons begin used for their normal purpose, which is to indicate the end of a command. $$ is now the delimiter until DELIMITER ; which then changes the semi-colon back it its normal purpose as a delimiter.

We could also prevent a user from following themself on instagram:

DELIMITER $$

	CREATE TRIGGER example_cannot_follow_self
		 BEFORE INSERT ON follows FOR EACH ROW
		 BEGIN
			  IF NEW.follower_id = NEW.followee_id
			  THEN
				   SIGNAL SQLSTATE '45000'
						SET MESSAGE_TEXT = 'Cannot follow yourself, silly';
			  END IF;
		 END;
	$$

	DELIMITER ;
	
2. Create new data from an existing transaction. Say a user un-follows somebody else, and instead of just deleting the relationship you want to keep some kind of record.

	DELIMITER $$

	CREATE TRIGGER create_unfollow
		AFTER DELETE ON follows FOR EACH ROW 
	BEGIN
		INSERT INTO unfollows      // an existing table
		SET follower_id = OLD.follower_id,  // accessing to deletedSHOW data
			followee_id = OLD.followee_id;
	END$$

	DELIMITER ;
	
To see all triggers run SHOW TRIGGERS;

Remove a trigger: DROP TRIGGER trigger_name;

warning: triggers can make debugging hard, especially when they are chained together. Typically there is an alternative to using a trigger.



Express Full stack app
------------------------------

$ node app.js

app.js:

var mysql = require('mysql');
const express = require('express');
const bodyParser = require('body-parser');

const app = express();

// ejs allows us to insert dynamic code into HTML: <%=data%>
app.set("view engine", "ejs");
// tidy up reponse body into JS object
app.use(bodyParser.urlencoded({extended: true}));
// serve up files such as CSS files from a public folder
app.use(express.static(__dirname + "/public"));

app.post("/register", function(req, res){
	const email = req.body.email;
	console.log(email);
	const person = {email};
	const q = 'INSERT INTO users SET ?';
	
	const connection = mysql.createConnection({
	  host     : 'localhost',
	  user     : 'root',     // your root username
	  database : 'joinus'   // the name of your db
	});
	
	connection.query(q, person, function(err, result) {
		if(err) throw err;
		console.log(result);
		// res.send('thanks for joining our list'); // HTML
		res.redirect('/'); // redirect back to the home page
		connection.end();
	})
})

app.get('/', function(req, res) {
	
	console.log('someone made a request')
	
	const connection = mysql.createConnection({
	  host     : 'localhost',
	  user     : 'root',     // your root username
	  database : 'joinus'   // the name of your db
	});
	
	const q = 'SELECT COUNT(*) AS total FROM users;'
	
	connection.query(q, function(err, result) {
		
		if(err) throw err;
		const dbResult = result[0].total;
		// async call back so must use send, render, redirect here.
		res.render("home", {count: dbResult});
		connection.end();
	});
})

// start the server
app.listen(3000, function() {
	console.log('server listening on port 3000');
})


HTML: by default ejs files live in a top level 'views' folder.


views/home.ejs:

<link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400" rel="stylesheet">
<link rel="stylesheet" href="/index.css">

<div class="flex-container">
    <div class="container">
        <h1>JOIN US</h1>
        <p class="lead">Enter your email to join <strong><%= count %></strong> others on our waitlist. We are 100% not a cult. </p>
        <form method="POST" action='/register'>
            <input type="text" name="email" class="form" placeholder="Enter Your Email">
            <button>Join Now</button>
        </form>
    </div>
</div>















